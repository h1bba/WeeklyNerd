<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="UTF-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>IO Digital</title>
  </head>
  <body>
    <p>
      IO Digital is een digital agency die met grote namen samen werken, het
      gebouw is ontzettend mooi en het ziet er uit alsof de collegas dagelijks
      een warm maaltijd bereid krijgen.
    </p>

    <p>
      Dave Bitter is oud CMD student en zit nu bij IO Digital als manager. Hij
      gaat ons vertellen over: The rise of AI powered voice interfaces (on the
      web)
    </p>

    <p>
      Voice recognition zit meer in ons leven dan ooit, er is een verandering
      gaande met hoe wij mensen informatie innemen. Dave heeft daarom een
      prototype gebouwd van een AI speech bot die terug met je kan praten.
    </p>

    <p>
      Veel oudere developers kijken niet meer terug naar features waarmee ze
      geen goede ervaringen hebben gehad, een van deze is de SpeechRecognition.
      Vroeger maakte dit veel fouten en klonk het ook nog eens robotisch en
      sloom. Nu is dat geupdate en is het al een stuk beter. We kunnen
      useSpeechRecognition voor input gebruiken en useSpeechSynthesis voor
      output. Er is ook is er een useConversation feature die op deze aansluit.
    </p>

    <p>
      Met ElevenLabs kan je een mooie stem genereren voor je speech "bot", je
      kan AI dan verbinden met je website en tussentijds deze stem het antwoord
      laten genereren. Dit is momenteel nog een beetje onhandig omdat er dan
      audio delay ontstaat doordat er een externe factor is waar we op wachten.
    </p>

    <p>
      Dave laat in zijn prototype zien dat de conversatie ook belangrijk is om
      te laten zien, dus denkt de computer even na, geef de gebruiker dan ook
      feedback dat dit gebeurt. Dave stelt hierbij voor dat performance boven
      alles gaat, de lange wachttijd verbreekt de illusie van conversatie. Dave
      probeert hier een lijn te trekken dat alle AI tech best cool kan zijn,
      maar dat UX boven alles staat en daardoor veel van de huidige AI nog een
      tikkeltje vroeg maakt om werkelijk in de praktijk te gebruiken.
    </p>

    <p>
      Steve Jonk is een programmeur bij IO Digital en laat ons zien hoe hij een
      Twitter/X follow bot en follow scraper heeft gebouwd. De X API vraagt voor
      enterprise API gebruik ontzettend veel geld, en Steve heeft er voor
      gezorgd dat hij dit kan omzeilen door zelf een web scraper te maken.
    </p>

    <p>
      Steve die heeft X een beetje uit elkaar getrokken en kwam er achter dat de
      volgers lijst van de accounts werkt met parameter pagination, en elke
      pagina laad 50 volgers zien, waardoor je met pagination steeds 50 nieuwe
      volgers kan vinden.
    </p>

    <p>
      Vervolgens heeft hij wat tools bij elkaar gebruikt om dit een werkend
      systeem te laten worden. N8N - voor workflow automation, Puppeteer voor
      browser automation, Twitter API voor de data, Postgres voor database,
      Docker voor containerisation en Ubuntu voor de server.
    </p>

    <p>
      Clarke Verdel - How do you automate testing your components like a real
      user? Op welke manieren kunnen we testen? Momenteel kunnen we E2E testen
      (end to end test), Integration testing en Component/Unit testing. We
      kunnen voordat we het product testen ook al binnen de code een aantal
      dingen testen, zoals linting en JavaScript type checker (TypeScript doet
      dit voor je).
    </p>

    <p>
      Je kan je code testen met Node Runtime: Kijken of de juiste modules etc
      installeren en werkend is. een Synthetic DOM: Een Synthetische Dom zou
      kijken of alle knoppen klikbaar zijn en of de links etc. Browser testing:
      dit is naar mijn mening het best omdat je zo dicht mogelijk bij de
      realiteit komt. Alle 3 de methodes hebben zijn eigen voordelen en nadelen,
      zo zou de Node Runtime niet weten of een knop wel of niet werkt.
    </p>
  </body>
</html>
